from sklearn.datasets import make_regression
import numpy as np


X,y = make_regression(n_samples=4, n_features=1, n_informative=1, n_targets=1,noise=80,random_state=13)
     


import matplotlib.pyplot as plt
plt.scatter(X,y)


#lets apply ordinary least square method
from sklearn.linear_model import LinearRegression


reg=LinearRegression()


reg.fit(X,y)


reg.coef_ #yo vameko m ho


reg.intercept_ # yo vaneko b ho 


plt.scatter(X,y)
plt.plot(X,reg.predict(X),color='red')



# Lets apply Gradient Descent assuming slope is constant m = 78.35
# and let's assume the starting value for intercept b = 100
y_pred = ((78.35 * X) + 100).reshape(4)


plt.scatter(X,y)
plt.plot(X,reg.predict(X),color='red' ,label='OLS')
plt.plot(X,y_pred,color='blue',label='b=100')
plt.legend()



m=78.35
b=100
loss_function_slope=-2*np.sum(y-m*X.ravel()-b)
loss_function_slope


# lets take learning rate 0.1 or take 0.01 or less
lr=0.1
step_size=loss_function_slope*lr
step_size


b=b-step_size #bnew=bold-learningrate*slope
b


#b=0 100 xa hai
#yo ho first iteration
y_pred1 = ((78.35 * X) + b).reshape(4)

plt.scatter(X,y)
plt.plot(X,reg.predict(X),color='red',label='OLS')
plt.plot(X,y_pred1,color='#00a65a',label='b = {}'.format(b))
plt.plot(X,y_pred,color='#A3E4D7',label='b = 100')
plt.legend()


#iteration 2
loss_function_slope=-2 * np.sum(y - m*X.ravel() - b)
loss_function_slope


step_size = loss_function_slope*lr
step_size


b = b - step_size
b


y_pred2 = ((78.35 * X) + b).reshape(4)
plt.scatter(X,y)
plt.plot(X,reg.predict(X),color='red',label='OLS')
plt.plot(X,y_pred2,color='green',label='b2 = {}'.format(b))
plt.plot(X,y_pred1,color='blue',label='b1 = 40.92')
plt.plot(X,y_pred,color='black',label='b = 100')
plt.legend()


# Iteration 3
loss_slope = -2 * np.sum(y - m*X.ravel() - b)
loss_slope


step_size = loss_slope*lr
step_size


b = b - step_size
b


y_pred3 = ((78.35 * X) + b).reshape(4)

plt.figure(figsize=(15,15))
plt.scatter(X,y)
plt.plot(X,reg.predict(X),color='red',label='OLS')
plt.plot(X,y_pred3,color='grey',label='b3 = {}'.format(b))
plt.plot(X,y_pred2,color='green',label='b2 = 29.11')
plt.plot(X,y_pred1,color='blue',label='b1 =40.92')
plt.plot(X,y_pred,color='black',label='b = 100')
plt.legend()
plt.show()


# now using for loop lets see the result
b=-100
m=78.35
lr=0.01
epochs=100
for i in range(epochs):
    loss_slope=-2*np.sum(y-m*X.ravel() -b)
    b=b-(lr*loss_slope)
    y_pred=m*X+b
    plt.plot(X,y_pred)

plt.scatter(X,y)




